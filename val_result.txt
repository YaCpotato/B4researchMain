wrn_28_10 model built as child model.
 Model summary:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 160)  23200       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 160)  640         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 160)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 160)  230560      activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 160)  640         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 160)  2720        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 160)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 160)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 160)  230560      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 160)  230560      activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 160)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 160)  230560      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 160)  230560      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 160)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 160)  230560      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 160)  230560      activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 160)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 160)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  461120      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 320)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 320)  921920      activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 320)  1280        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 320)  51520       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 320)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 320)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 320)  921920      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 320)  921920      activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 320)  1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 320)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 320)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 320)  921920      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 320)  921920      activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 320)  1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 320)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 320)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 320)  921920      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 320)  1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 320)  921920      activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 320)  1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 320)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 320)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 320)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 640)    1843840     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 640)    2560        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 640)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 640)    3687040     activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 640)    2560        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 640)    205440      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 640)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 640)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 640)    3687040     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 640)    2560        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 640)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 640)    3687040     activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 640)    2560        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 640)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 640)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 640)    3687040     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 640)    2560        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 640)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 640)    3687040     activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 640)    2560        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 640)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 640)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 640)    3687040     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 640)    2560        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 640)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 640)    3687040     activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 640)    2560        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 640)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 640)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 640)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           6410        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,507,242
Trainable params: 36,489,290
Non-trainable params: 17,952
__________________________________________________________________________________________________
None
fitting the model
Epoch 1/100
Policies are:
[{'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.946, 'aug2_type': 'gamma-contrast', 'aug2_magnitude': 0.8490000000000001}, {'aug1_type': 'crop', 'aug1_magnitude': 0.897, 'aug2_type': 'invert', 'aug2_magnitude': 0.024}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.825, 'aug2_type': 'horizontal-flip', 'aug2_magnitude': 0.022}, {'aug1_type': 'translate-x', 'aug1_magnitude': 0.334, 'aug2_type': 'fog', 'aug2_magnitude': 0.462}, {'aug1_type': 'crop', 'aug1_magnitude': 0.8809999999999999, 'aug2_type': 'emboss', 'aug2_magnitude': 0.06}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.334, 'aug2_type': 'crop', 'aug2_magnitude': 0.299}, {'aug1_type': 'add-to-hue-and-saturation', 'aug1_magnitude': 0.478, 'aug2_type': 'shear', 'aug2_magnitude': 0.195}, {'aug1_type': 'vertical-flip', 'aug1_magnitude': 0.654, 'aug2_type': 'shear', 'aug2_magnitude': 0.207}, {'aug1_type': 'add-to-hue-and-saturation', 'aug1_magnitude': 0.157, 'aug2_type': 'coarse-dropout', 'aug2_magnitude': 0.201}, {'aug1_type': 'crop', 'aug1_magnitude': 0.858, 'aug2_type': 'translate-x', 'aug2_magnitude': 0.262}, {'aug1_type': 'add-to-hue-and-saturation', 'aug1_magnitude': 0.047, 'aug2_type': 'vertical-flip', 'aug2_magnitude': 0.212}, {'aug1_type': 'rotate', 'aug1_magnitude': 0.7190000000000001, 'aug2_type': 'fog', 'aug2_magnitude': 0.029}, {'aug1_type': 'brighten', 'aug1_magnitude': 0.342, 'aug2_type': 'gaussian-blur', 'aug2_magnitude': 0.966}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.813, 'aug2_type': 'translate-y', 'aug2_magnitude': 0.025}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.894, 'aug2_type': 'brighten', 'aug2_magnitude': 0.973}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.487, 'aug2_type': 'shear', 'aug2_magnitude': 0.34}, {'aug1_type': 'add-to-hue-and-saturation', 'aug1_magnitude': 0.358, 'aug2_type': 'fog', 'aug2_magnitude': 0.196}, {'aug1_type': 'crop', 'aug1_magnitude': 0.952, 'aug2_type': 'shear', 'aug2_magnitude': 0.487}, {'aug1_type': 'add-to-hue-and-saturation', 'aug1_magnitude': 0.032, 'aug2_type': 'clouds', 'aug2_magnitude': 0.931}, {'aug1_type': 'clouds', 'aug1_magnitude': 0.688, 'aug2_type': 'fog', 'aug2_magnitude': 0.001}, {'aug1_type': 'shear', 'aug1_magnitude': 0.009000000000000001, 'aug2_type': 'additive-gaussian-noise', 'aug2_magnitude': 0.069}, {'aug1_type': 'gaussian-blur', 'aug1_magnitude': 0.517, 'aug2_type': 'translate-y', 'aug2_magnitude': 0.026}, {'aug1_type': 'translate-x', 'aug1_magnitude': 0.319, 'aug2_type': 'translate-y', 'aug2_magnitude': 0.28600000000000003}, {'aug1_type': 'crop', 'aug1_magnitude': 0.8959999999999999, 'aug2_type': 'brighten', 'aug2_magnitude': 0.5720000000000001}, {'aug1_type': 'rotate', 'aug1_magnitude': 0.335, 'aug2_type': 'dropout', 'aug2_magnitude': 0.121}, {'aug1_type': 'crop', 'aug1_magnitude': 0.5760000000000001, 'aug2_type': 'coarse-salt-pepper', 'aug2_magnitude': 0.017}, {'aug1_type': 'fog', 'aug1_magnitude': 0.35, 'aug2_type': 'gaussian-blur', 'aug2_magnitude': 0.106}, {'aug1_type': 'gaussian-blur', 'aug1_magnitude': 0.894, 'aug2_type': 'clouds', 'aug2_magnitude': 0.025}, {'aug1_type': 'brighten', 'aug1_magnitude': 0.07, 'aug2_type': 'add-to-hue-and-saturation', 'aug2_magnitude': 0.165}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.508, 'aug2_type': 'gaussian-blur', 'aug2_magnitude': 0.986}]

 - 157s - loss: 2.5125 - acc: 0.2050 - val_loss: 1.9704 - val_acc: 0.3560
Epoch 2/100
 - 154s - loss: 1.9100 - acc: 0.3019 - val_loss: 1.4492 - val_acc: 0.4678
Epoch 3/100
 - 150s - loss: 1.7555 - acc: 0.3640 - val_loss: 1.2680 - val_acc: 0.5495
Epoch 4/100
 - 149s - loss: 1.6426 - acc: 0.4073 - val_loss: 1.0856 - val_acc: 0.6322
Epoch 5/100
 - 149s - loss: 1.5567 - acc: 0.4441 - val_loss: 0.8313 - val_acc: 0.7115
Epoch 6/100
 - 149s - loss: 1.4926 - acc: 0.4675 - val_loss: 0.8518 - val_acc: 0.7098
Epoch 7/100
 - 152s - loss: 1.4281 - acc: 0.4906 - val_loss: 0.9637 - val_acc: 0.6547
Epoch 8/100
 - 150s - loss: 1.3903 - acc: 0.5050 - val_loss: 0.8017 - val_acc: 0.7185
Epoch 9/100
 - 148s - loss: 1.3528 - acc: 0.5177 - val_loss: 0.6994 - val_acc: 0.7653
Epoch 10/100
 - 147s - loss: 1.3014 - acc: 0.5365 - val_loss: 0.6003 - val_acc: 0.7822
Epoch 11/100
 - 147s - loss: 1.2683 - acc: 0.5504 - val_loss: 0.5222 - val_acc: 0.8203
Epoch 12/100
 - 148s - loss: 1.2506 - acc: 0.5556 - val_loss: 0.5041 - val_acc: 0.8322
Epoch 13/100
 - 147s - loss: 1.2129 - acc: 0.5682 - val_loss: 0.5678 - val_acc: 0.8093
Epoch 14/100
 - 147s - loss: 1.2264 - acc: 0.5624 - val_loss: 0.4824 - val_acc: 0.8417
Epoch 15/100
 - 145s - loss: 1.1810 - acc: 0.5768 - val_loss: 0.4715 - val_acc: 0.8483
Epoch 16/100
 - 152s - loss: 1.1552 - acc: 0.5882 - val_loss: 0.4336 - val_acc: 0.8517
Epoch 17/100
 - 151s - loss: 1.1565 - acc: 0.5865 - val_loss: 0.6781 - val_acc: 0.7847
Epoch 18/100
 - 150s - loss: 1.1389 - acc: 0.5909 - val_loss: 0.5248 - val_acc: 0.8305
Epoch 19/100
 - 148s - loss: 1.1191 - acc: 0.6007 - val_loss: 0.4130 - val_acc: 0.8705
Epoch 20/100
 - 148s - loss: 1.1068 - acc: 0.6030 - val_loss: 0.5110 - val_acc: 0.8328
Epoch 21/100
 - 147s - loss: 1.1070 - acc: 0.6046 - val_loss: 0.4050 - val_acc: 0.8673
Epoch 22/100
 - 151s - loss: 1.0890 - acc: 0.6089 - val_loss: 0.4303 - val_acc: 0.8625
Epoch 23/100
 - 152s - loss: 1.0602 - acc: 0.6199 - val_loss: 0.3967 - val_acc: 0.8703
Epoch 24/100
 - 149s - loss: 1.0532 - acc: 0.6219 - val_loss: 0.3730 - val_acc: 0.8775
Epoch 25/100
 - 149s - loss: 1.0556 - acc: 0.6207 - val_loss: 0.3609 - val_acc: 0.8793
Epoch 26/100
 - 147s - loss: 1.0419 - acc: 0.6270 - val_loss: 0.3415 - val_acc: 0.8908
Epoch 27/100
 - 149s - loss: 1.0400 - acc: 0.6272 - val_loss: 0.3378 - val_acc: 0.8863
Epoch 28/100
 - 147s - loss: 1.0387 - acc: 0.6282 - val_loss: 0.3584 - val_acc: 0.8893
Epoch 29/100
 - 153s - loss: 1.0183 - acc: 0.6349 - val_loss: 0.3462 - val_acc: 0.8932
Epoch 30/100
 - 150s - loss: 1.0242 - acc: 0.6356 - val_loss: 0.3849 - val_acc: 0.8830
Epoch 31/100
 - 152s - loss: 1.0135 - acc: 0.6375 - val_loss: 0.3613 - val_acc: 0.8942
Epoch 32/100
 - 151s - loss: 1.0073 - acc: 0.6388 - val_loss: 0.3552 - val_acc: 0.8930
Epoch 33/100
 - 148s - loss: 0.9962 - acc: 0.6423 - val_loss: 0.3459 - val_acc: 0.8963
Epoch 34/100
 - 153s - loss: 0.9827 - acc: 0.6483 - val_loss: 0.4049 - val_acc: 0.8837
Epoch 35/100
 - 145s - loss: 1.0003 - acc: 0.6406 - val_loss: 0.3410 - val_acc: 0.8960
Epoch 36/100
 - 147s - loss: 0.9795 - acc: 0.6499 - val_loss: 0.3145 - val_acc: 0.9040
Epoch 37/100
 - 152s - loss: 0.9783 - acc: 0.6496 - val_loss: 0.3931 - val_acc: 0.8878
Epoch 38/100
 - 151s - loss: 0.9726 - acc: 0.6533 - val_loss: 0.4291 - val_acc: 0.8782
Epoch 39/100
 - 150s - loss: 0.9798 - acc: 0.6478 - val_loss: 0.2895 - val_acc: 0.9073
Epoch 40/100
 - 147s - loss: 0.9591 - acc: 0.6565 - val_loss: 0.3934 - val_acc: 0.8793
Epoch 41/100
 - 152s - loss: 0.9535 - acc: 0.6562 - val_loss: 0.3788 - val_acc: 0.8850
Epoch 42/100
 - 152s - loss: 0.9649 - acc: 0.6524 - val_loss: 0.4717 - val_acc: 0.8702
Epoch 43/100
 - 147s - loss: 0.9455 - acc: 0.6623 - val_loss: 0.3473 - val_acc: 0.9015
Epoch 44/100
 - 147s - loss: 0.9459 - acc: 0.6599 - val_loss: 0.3819 - val_acc: 0.8943
Epoch 45/100
 - 146s - loss: 0.9577 - acc: 0.6572 - val_loss: 0.3328 - val_acc: 0.9077
Epoch 46/100
 - 147s - loss: 0.9342 - acc: 0.6633 - val_loss: 0.3564 - val_acc: 0.8988
Epoch 47/100
 - 147s - loss: 0.9218 - acc: 0.6697 - val_loss: 0.3416 - val_acc: 0.9037
Epoch 48/100
 - 147s - loss: 0.9235 - acc: 0.6691 - val_loss: 0.3429 - val_acc: 0.9025
Epoch 49/100
 - 148s - loss: 0.9333 - acc: 0.6661 - val_loss: 0.3538 - val_acc: 0.9060
Epoch 50/100
 - 150s - loss: 0.9386 - acc: 0.6648 - val_loss: 0.3362 - val_acc: 0.9042
Epoch 51/100
 - 147s - loss: 0.9342 - acc: 0.6655 - val_loss: 0.3733 - val_acc: 0.8982
Epoch 52/100
 - 149s - loss: 0.9168 - acc: 0.6718 - val_loss: 0.3352 - val_acc: 0.9027
Epoch 53/100
 - 146s - loss: 0.9238 - acc: 0.6694 - val_loss: 0.3542 - val_acc: 0.8985
Epoch 54/100
 - 144s - loss: 0.9306 - acc: 0.6673 - val_loss: 0.2934 - val_acc: 0.9120
Epoch 55/100
 - 147s - loss: 0.9121 - acc: 0.6737 - val_loss: 0.3144 - val_acc: 0.9097
Epoch 56/100
 - 152s - loss: 0.9126 - acc: 0.6708 - val_loss: 0.3044 - val_acc: 0.9135
Epoch 57/100
 - 149s - loss: 0.9060 - acc: 0.6743 - val_loss: 0.4156 - val_acc: 0.8975
Epoch 58/100
 - 148s - loss: 0.9124 - acc: 0.6751 - val_loss: 0.3090 - val_acc: 0.9045
Epoch 59/100
 - 151s - loss: 0.9093 - acc: 0.6748 - val_loss: 0.3544 - val_acc: 0.9105
Epoch 60/100
 - 146s - loss: 0.9086 - acc: 0.6743 - val_loss: 0.2852 - val_acc: 0.9173
Epoch 61/100
 - 149s - loss: 0.8989 - acc: 0.6771 - val_loss: 0.3486 - val_acc: 0.9105
Epoch 62/100
 - 148s - loss: 0.8993 - acc: 0.6777 - val_loss: 0.3696 - val_acc: 0.9030
Epoch 63/100
 - 150s - loss: 0.8840 - acc: 0.6834 - val_loss: 0.3381 - val_acc: 0.9053
Epoch 64/100
 - 151s - loss: 0.9028 - acc: 0.6762 - val_loss: 0.3326 - val_acc: 0.9107
Epoch 65/100
 - 151s - loss: 0.8953 - acc: 0.6798 - val_loss: 0.3438 - val_acc: 0.9017
Epoch 66/100
 - 146s - loss: 0.8968 - acc: 0.6777 - val_loss: 0.2927 - val_acc: 0.9172
Epoch 67/100
 - 149s - loss: 0.8906 - acc: 0.6798 - val_loss: 0.2703 - val_acc: 0.9210
Epoch 68/100
 - 149s - loss: 0.9053 - acc: 0.6730 - val_loss: 0.3067 - val_acc: 0.9167
Epoch 69/100
 - 151s - loss: 0.8946 - acc: 0.6800 - val_loss: 0.3278 - val_acc: 0.9043
Epoch 70/100
 - 148s - loss: 0.8861 - acc: 0.6822 - val_loss: 0.3171 - val_acc: 0.9065
Epoch 71/100
 - 150s - loss: 0.8880 - acc: 0.6818 - val_loss: 0.2703 - val_acc: 0.9253
Epoch 72/100
 - 148s - loss: 0.8826 - acc: 0.6843 - val_loss: 0.3045 - val_acc: 0.9195
